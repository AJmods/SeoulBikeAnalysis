---
title: "Seoul Bike Dataset"
author: "Andrew Danda, 구민우, 방설화"
date: "`r Sys.Date()`"
documentclass: article
fontsize: 11pt 
geometry: margin=0.7in
output: pdf_document
header-includes:
  - \usepackage{kotex}
  - \usepackage{palatino}
  - \usepackage{enumerate}
  - \usepackage[onehalfspacing]{setspace}
  - \usepackage{hyperref}
  - \usepackage{amsthm}
  - \usepackage{enumitem}
  - \newtheoremstyle{sol}{3pt}{2pt}{}{}{\bfseries}{.}{.5em}{}
  - \theoremstyle{sol}
  - \newtheorem*{sol}{Suggested Solution}
  - \newcommand{\benum}{\begin{enumerate}}
  - \newcommand{\eenum}{\end{enumerate}}
  - \newcommand{\bitem}{\begin{itemize}}
  - \newcommand{\eitem}{\end{itemize}}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, prompt=FALSE, message = FALSE,comment=NA )
```
# Question
Can we predict the number of riders using the Seoul Bike Sharing based on the date and the weather?

# Methods
We plan on using Lasso, Ridge, Decision tree and Random forest for this Dataset.

## The Dataset

This is a dataset containing Seoul Bike sharing ridership from December 1, 2017 to November 30, 2018.

\small
\begin{center}
\centering
\begin{table}[htb!]
\centering
\begin{tabular}{cl}
\hline 
\multicolumn{2}{c}{Dependent variable}\\
\hline 
$Rented_Bike_Count$&The number of bikes rented\\
\hline \hline	
\multicolumn{2}{c}{Independent variables} \\
\hline
\multicolumn{2}{l}{1. Time Varibles} \\
\hline
$Date$&The Date (dd/mm/yyyy)\\
$Hour$&The Hour (integer between 1 and 24)\\
$Holiday$&Dummy variable if the day is a holiday or not\\
$Weekend$&Dummy variable if the day is a weekend or not\\
$FunctionalDay$&Dummy variable if the bikes were functional or not\\
$Seasons_Spring$&Dummy variable if the season is Spring or not\\
$Seasons_Summer$&Dummy variable if the season is Summer or not\\
$Seasons_Autumn$&Dummy variable if the season is Autumn or not\\
$Seasons_Winter$&Dummy variable if the season is Winter or not\\
\hline 
\multicolumn{2}{l}{2. Weather varibles}\\
\hline
$Temperature$&Temperature in Celsius\\
$Humidity$&Humidity ($\%$)\\
$Wind_Speed$&Wind speed in meters per second\\
$Visibility$&Visibility in Kilometers\\
$Dew_Point_Temperature$&Dew Point Temperature in Celsius\\
$Solor_Radiation$&Solar Radiation in millijoules Per square meter\\
$Rainfall$&Rainfall in millimeters\\
$Snowfall$&Snowfall in centimeters\\
\hline
\end{tabular}
\end{table}
\end{center}
\normalsize


```{r librarys}
library(tidyverse)
library(dplyr)
library(fastDummies)
```

```{r data}
bikeData <- read.csv("SeoulBikeData.csv", stringsAsFactors=FALSE, fileEncoding="latin1")

# Clean dataset

# rename columns
bikeData <- bikeData %>%
  rename("Rented_Bike_Count" = "Rented.Bike.Count",
         "Temperature" = "Temperature..C.",
         "Humidity" = "Humidity...",
         "Wind_Speed"= "Wind.speed..m.s.",
         "Visibility" = "Visibility..10m.",
         "Dew_Point_Temperature" = "Dew.point.temperature..C.",
         "Solar_Radiation" = "Solar.Radiation..MJ.m2.",
         "Rainfall" = "Rainfall.mm.",
         "Snowfall" = "Snowfall..cm.",
         "Functioning_Day" = "Functioning.Day")

#divide the visibility by 100 to change it's units from 10s of meters to kilometers
bikeData$Visibility <- bikeData$Visibility / 100

#add weekend variable
bikeData$Weekend <- ifelse(lubridate::wday(as.Date(bikeData$Date,format = "%d/%m/%Y"), week_start = 1) > 5,1,0)
#lubridate::wday(as.Date("21/04/2024",format = "%d/%m/%Y"),label = TRUE, week_start = 1)

# Dummy variables
bikeData$Holiday <- ifelse(bikeData$Holiday == "No Holiday", 0, 1)
bikeData$Functioning_Day <- ifelse(bikeData$Functioning_Day == "Yes", 1, 0)

#Holiday Dummies
bikeData <- bikeData %>% dummy_cols(select_columns = c("Seasons"))


#remove all data where functioning day is false
#We will only use data where the bikes are functioning.
bikeData <- bikeData %>% filter(Functioning_Day == 1)

#combine weekend with holidays
# let's use this variable instead of weekend and holidays.  
bikeData$wkdHol <- ifelse(bikeData$Holiday == 1 | bikeData$Weekend == 1, 1, 0)

bikeData <- bikeData %>% subset(select= -c(Holiday,Weekend,Date, Functioning_Day, Seasons))

# summary(bikeData)
```

``` {r trainDataset}

# Split dataset into test and train.
set.seed(42069)
train_index<-sample(c(TRUE,FALSE),nrow(bikeData),replace=TRUE, prob=c(.8,.2))

bikeData.train <- bikeData[train_index,]
bikeData.test <- bikeData[!train_index,]

#Check number of observations
nrow(bikeData.train)
nrow(bikeData.test)

```
# Running Random Forest
We are using rftune() to for randomForest.  It finds the perfect mtry and tunes the model.
```{r tune}
library(randomForest)
library(doMC)
#install.packages("doMC", repos="http://R-Forge.R-project.org")

registerDoMC(6) 
# this model takes a long time to train, so if we have the file on hand then let's use it.  
trainNewModel = FALSE
file_name <- "bikingInARandomForest.rds"

if (trainNewModel | !file.exists(file_name)) {
  bag.bikes.train <- tuneRF(bikeData.train[,-1], bikeData.train[,1],ntreeTry = 2000,stepFactor=1.5, improve=0.01, doBest = TRUE)

    #Save model
  saveRDS(bag.bikes.train,file_name)


} else {
  bag.bikes.train <- readRDS(file_name)

  #bag.bikes.train <- as_parsed_model(loaded_model)
}
# bag.bikes.train

```
```{r randomForest}
#library(randomForest)
#big.bikes.train = randomForest(Rented_Bike_Count~.,data=bikeData.train, mtry=best_mtry, importance =TRUE,ntree=2000)

#big.bikes.train
```

# Mean Squared Error
```{r}
resid=bikeData.train$Rented_Bike_Count-bag.bikes.train$predicted
mse=mean(resid^2)
mse
```
# Tree graph
```{r}
df_numtree<-data.frame(num_tree=seq(1,500,length.out=500), mse=bag.bikes.train$mse)
ggplot(aes(x=num_tree,y=mse),data=df_numtree)+
  geom_line(color="blue")+
  ylab("OOB MSE")+xlab("Number of trees in bagging")+
 theme(plot.title = element_text(hjust = 0.5,size=14),
          panel.background = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          axis.title=element_text(size=11),
          axis.line = element_line(colour = "gray"))
```
# Prediction
```{r, collapse=TRUE, fig.align='center'}

bag.predict = predict (bag.bikes.train ,newdata =bikeData.test)

# plot Rented Bike Count and the predicted Rented Bike Count. How well they line up with the 45 degree line?
plot(bag.predict,bikeData.test$Rented_Bike_Count,ylab="Predicted Rented Bike Count",
     xlab="Actual Rented Bike Count", main="bagging")
abline(0,1)

# compute the prediction error 
bag.te<-mean((bikeData.test$Rented_Bike_Count-bag.predict)^2)
bag.te
```

```{r importance}
df.relative.imp<-data.frame(vars=rownames(bag.bikes.train$importance),rel_imp=(bag.bikes.train$importance[,1]/bag.bikes.train$importance[which.max(bag.bikes.train$importance[,1]),1])*100)

df.relative.imp<-df.relative.imp[order(-df.relative.imp$rel_imp),]

gout_varimp<-ggplot(data=df.relative.imp[1:10,],aes(x=reorder(vars, rel_imp),y=rel_imp)) +
  geom_bar(stat="identity", fill="gray70")+coord_flip()+
  geom_text(aes(label=vars), vjust=0,color="lightblue4", size=4)+
  ggtitle("Relative Variable Importance measured with reduced RSS")+
  ylab("relative importance")+
  xlab("variables")+
  theme(plot.title = element_text(hjust = 0.5,size=13),
          panel.background = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          axis.title=element_text(size=11),
          axis.line = element_line(colour = "gray"))
gout_varimp
```